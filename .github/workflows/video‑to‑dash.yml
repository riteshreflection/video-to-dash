name: Convert uploaded video to DASH

on:
  repository_dispatch:
    types: [video_uploaded]

  workflow_dispatch:
    inputs:
      publicUrl:
        description: "Direct URL to the source MP4 (https://.../file.mp4)"
        required: true
      key:
        description: "Destination key in R2 (optional, e.g. uploads/my.mp4)"
        required: false

env:
  R2_BUCKET: classes
  ACCOUNT_ID: ${{ secrets.ACCOUNT_ID }}
  R2_ENDPOINT: https://300ec3f71b1ad69fea75564497e04614.r2.cloudflarestorage.com

jobs:
  transcode:
    runs-on: ubuntu-latest
    environment: CloudFlare Secretary
    timeout-minutes: 60

    steps:
    - name: Checkout (empty repo)
      uses: actions/checkout@v4
      with:
        sparse-checkout: ""

    - name: Derive SOURCE_URL and KEY
      id: derive
      run: |
        set -euo pipefail

        # 1. SOURCE_URL â€“ prefer repository_dispatch, fallback to manual input
        SOURCE_URL="${{ github.event.client_payload.publicUrl }}"
        if [ -z "$SOURCE_URL" ]; then
          SOURCE_URL="${{ github.event.inputs.publicUrl }}"
        fi

        # 2. KEY â€“ prefer payload key, fallback to manual input
        KEY="${{ github.event.client_payload.key }}"
        if [ -z "$KEY" ]; then
          KEY_INPUT="${{ github.event.inputs.key }}"
          if [ -n "$KEY_INPUT" ]; then
            KEY="$KEY_INPUT"
          else
            KEY="uploads/$(basename "$SOURCE_URL")"
          fi
        fi

        echo "SOURCE_URL=$SOURCE_URL" >> $GITHUB_ENV
        echo "KEY=$KEY"               >> $GITHUB_ENV

        echo "::notice::SOURCE_URL=$SOURCE_URL"
        echo "::notice::KEY=$KEY"

    - name: Install FFmpeg and AWS CLI
      run: |
        sudo apt-get update
        sudo apt-get install -y ffmpeg python3-pip
        python3 -m pip install --upgrade --user awscli
        echo "$HOME/.local/bin" >> $GITHUB_PATH

    - name: Download original MP4
      run: |
        mkdir -p work
        curl -L "$SOURCE_URL" --fail -o work/input.mp4
        du -h work/input.mp4

    - name: Convert to DASH (5 single segment files)
      run: |
        mkdir -p work/dash

        CLEAN_NAME=$(basename "$KEY" .mp4)
        [ -z "$CLEAN_NAME" ] && CLEAN_NAME="video_$(date +%s)"
        BASE="$CLEAN_NAME"

        ffmpeg -y -i work/input.mp4 \
          -map 0:v -c:v:0 libx264 -b:v:0 1500k -maxrate:v:0 1600k -bufsize:v:0 2000k -vf:0 scale=w=1280:h=-2:flags=bicubic \
          -map 0:v -c:v:1 libx264 -b:v:1 800k  -maxrate:v:1 900k  -bufsize:v:1 1200k -vf:1 scale=w=854:h=-2:flags=bicubic \
          -map 0:v -c:v:2 libx264 -b:v:2 400k  -maxrate:v:2 450k  -bufsize:v:2 600k -vf:2 scale=w=640:h=-2:flags=bicubic \
          -map 0:a -c:a aac -b:a 128k \
          -f dash -single_file 1 -min_seg_duration 5000000 \
          -adaptation_sets "id=0,streams=v id=1,streams=a" \
          "work/dash/${BASE}.mpd"

        echo "Generated files:"
        ls -lh work/dash

    - name: Upload DASH files to R2
      env:
        AWS_ACCESS_KEY_ID:     ${{ secrets.R2_ACCESS_KEY_ID }}
        AWS_SECRET_ACCESS_KEY: ${{ secrets.R2_SECRET_ACCESS_KEY }}
        AWS_EC2_METADATA_DISABLED: true
      run: |
        aws s3 cp work/dash/ "s3://${{ env.R2_BUCKET }}/dash/" --recursive \
          --endpoint-url "${{ env.R2_ENDPOINT }}"

    - name: Report summary
      run: |
        BASE=$(basename "$KEY" .mp4)
        echo "ðŸŽ‰ DASH manifest is ready:"
        echo "https://classes.thecampus.in/dash/${BASE}.mpd"
